{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e83245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Date               0\n",
       "Time               0\n",
       "Day                0\n",
       "Venue              0\n",
       "Result             0\n",
       "GF                 0\n",
       "GA                 0\n",
       "Opponent           0\n",
       "xG                 2\n",
       "xGA                2\n",
       "Poss               0\n",
       "Attendance       684\n",
       "Formation          0\n",
       "Opp Formation      0\n",
       "Sh                 0\n",
       "SoT                0\n",
       "Dist               4\n",
       "FK                 2\n",
       "PK                 0\n",
       "PKatt              0\n",
       "Season             0\n",
       "Team               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "data = pd.read_csv('matches_serie_A.csv')\n",
    "#removing unnecessary columns\n",
    "clean_data=data.drop(['Notes', 'Match Report','Comp','Captain','Referee','Round'], axis=1)\n",
    "clean_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f29b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Attendance\n",
    "home_avg_attendance = clean_data[clean_data['Venue'] == 'Home'].groupby('Team')['Attendance'].mean()\n",
    "\n",
    "# Filling missing attendances using home team avg attendacne\n",
    "def fill_attendance(row):\n",
    "    if pd.isna(row['Attendance']):\n",
    "        if row['Venue'] == 'Home':\n",
    "            return home_avg_attendance.get(row['Team'], clean_data['Attendance'].mean())\n",
    "        else:\n",
    "            return home_avg_attendance.get(row['Opponent'], clean_data['Attendance'].mean())\n",
    "    return row['Attendance']\n",
    "\n",
    "clean_data['Attendance'] = clean_data.apply(fill_attendance, axis=1)\n",
    "\n",
    "# Fill missing numeric stats with medians\n",
    "for col in ['xG', 'xGA', 'Dist', 'FK']:\n",
    "    clean_data[col] = clean_data[col].fillna(clean_data[col].median()) \n",
    "\n",
    "# Encode Result from string to ints (our prediction feature)\n",
    "clean_data['Result'] = clean_data['Result'].map({'W': 2, 'D': 1, 'L': 0})\n",
    "\n",
    "# Date processing\n",
    "clean_data['Date'] = pd.to_datetime(clean_data['Date'], format='mixed', dayfirst=True)\n",
    "clean_data = clean_data.sort_values(['Team', 'Date']).reset_index(drop=True)\n",
    "clean_data['Month'] = clean_data['Date'].dt.month\n",
    "\n",
    "#season stage encoding\n",
    "def season_stage(month): \n",
    "    if month in [8, 9, 10, 11]: return 0\n",
    "    elif month in [12, 1, 2]: return 1\n",
    "    else: return 2\n",
    "clean_data['SeasonStage'] = clean_data['Month'].apply(season_stage)\n",
    "\n",
    "# Venue encoding from strings to int\n",
    "clean_data['Venue'] = clean_data['Venue'].map({'Home': 1, 'Away': 0})\n",
    "\n",
    "# Time encoding into int\n",
    "clean_data['Hour'] = pd.to_datetime(clean_data['Time'], format=\"%H:%M\").dt.hour\n",
    "clean_data['TimeBinary'] = ((clean_data['Hour'] >= 18) | (clean_data['Hour'] < 6)).astype(int)\n",
    "clean_data.drop(['Time', 'Hour'], axis=1, inplace=True)\n",
    "\n",
    "# Day encoding from string to int\n",
    "day_mapping = {\"Mon\": 0, \"Tue\": 1, \"Wed\": 2, \"Thu\": 3, \"Fri\": 4, \"Sat\": 5, \"Sun\": 6}\n",
    "clean_data['Day'] = clean_data['Day'].map(day_mapping)\n",
    "\n",
    "# Formation encoding for a uniform formation\n",
    "def clean_and_split_formation(formation):\n",
    "    if pd.isna(formation): return [0, 0, 0, 0, 0]\n",
    "    formation = re.sub(r\"[^0-9\\-]\", \"\", str(formation))\n",
    "    parts = [int(x) for x in formation.split('-') if x.isdigit()]\n",
    "    while len(parts) < 5:\n",
    "        parts.append(0)\n",
    "    return parts[:5]\n",
    "\n",
    "for col in ['Formation', 'Opp Formation']:\n",
    "    split_data = clean_data[col].apply(clean_and_split_formation)\n",
    "    clean_data[[f\"{col}_{i}\" for i in range(1,6)]] = pd.DataFrame(split_data.tolist(), index=clean_data.index)\n",
    "clean_data.drop(['Formation', 'Opp Formation'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7221f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering \n",
    "stats_to_avg = ['xG', 'xGA', 'SoT', 'Sh', 'Poss', 'Dist', 'GF', 'GA'] # Average the relevant stats\n",
    "\n",
    "# Home/Away averages\n",
    "def calc_avg(df, stat, venue): # Group results\n",
    "    return (\n",
    "        df[df['Venue'] == venue]\n",
    "        .groupby('Team')[stat]\n",
    "        .transform(lambda x: x.shift(1).expanding().mean())\n",
    "    )\n",
    "\n",
    "for stat in stats_to_avg:\n",
    "    clean_data[f'Home_{stat}_avg'] = calc_avg(clean_data, stat, 1)\n",
    "    clean_data[f'Away_{stat}_avg'] = calc_avg(clean_data, stat, 0)\n",
    "\n",
    "# Recent form \n",
    "clean_data['WinRate_last5'] = ( # Rolling average win statistics for past 5 matches\n",
    "    clean_data.groupby('Team')['Result']\n",
    "    .transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean() / 2)\n",
    ").fillna(0)\n",
    "\n",
    "# Computes average statistics for past 5 matches in the 4 most important goals related stats\n",
    "for stat in ['GF', 'GA', 'xG', 'xGA']: \n",
    "    clean_data[f'{stat}_last5'] = (\n",
    "        clean_data.groupby('Team')[stat]\n",
    "        .transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())\n",
    "    )\n",
    "\n",
    "# Win, draw , lose streaks\n",
    "def get_streak(series, value):\n",
    "    streaks = []\n",
    "    current = 0\n",
    "    for res in series.shift(1):\n",
    "        if res == value:\n",
    "            current += 1\n",
    "        else:\n",
    "            current = 0\n",
    "        streaks.append(current)\n",
    "    return streaks\n",
    "\n",
    "clean_data['Win_Streak'] = clean_data.groupby('Team')['Result'].transform(lambda x: get_streak(x, 2)) # New feature - current win streak\n",
    "clean_data['Draw_Streak'] = clean_data.groupby('Team')['Result'].transform(lambda x: get_streak(x, 1)) # New feature - current draw streak\n",
    "clean_data['Loss_Streak'] = clean_data.groupby('Team')['Result'].transform(lambda x: get_streak(x, 0)) # New feature - current lose streak\n",
    "\n",
    "# Rest & fatigue days \n",
    "clean_data['RestDays'] = clean_data.groupby('Team')['Date'].diff().dt.days.fillna(7).clip(0, 14) # New feature - days passed from last match up to 14 days\n",
    "\n",
    "games_last_10 = [] # New feature - games played in last 10 days for each team\n",
    "for team, group in clean_data.groupby('Team'):\n",
    "    g = group.copy()\n",
    "    g = g.set_index('Date').sort_index()\n",
    "    g['Games_last10d'] = g['Team'].rolling('10D').count().shift(1)\n",
    "    games_last_10.append(g['Games_last10d'].reset_index(drop=True))\n",
    "clean_data['Games_last10d'] = pd.concat(games_last_10, ignore_index=True).fillna(0)\n",
    "\n",
    "# Elo rating \n",
    "def compute_elo(df, k=150, base=1500): # Assigns Elo rating for each team based on pre match data  , base elo is 1500\n",
    "    ratings, pre = {}, []\n",
    "    for _, row in df.iterrows():\n",
    "        t, o = row['Team'], row['Opponent']\n",
    "        ratings.setdefault(t, base)\n",
    "        ratings.setdefault(o, base)\n",
    "        pre.append(ratings[t])\n",
    "        exp = 1 / (1 + 10 ** ((ratings[o] - ratings[t]) / 400)) # standard elo formula (from chess)\n",
    "        ratings[t] += k * ((row['Result'] / 2) - exp)\n",
    "    return pre\n",
    "\n",
    "clean_data['Elo'] = compute_elo(clean_data, k=150)\n",
    "last_elo = clean_data.groupby('Team')['Elo'].shift(1).fillna(1500)\n",
    "opp_elo = clean_data.merge(\n",
    "    clean_data[['Team', 'Date', 'Elo']],\n",
    "    left_on=['Opponent', 'Date'],\n",
    "    right_on=['Team', 'Date'],\n",
    "    how='left', suffixes=('', '_opp')\n",
    ")['Elo_opp'].fillna(1500)\n",
    "\n",
    "clean_data['Elo_Diff'] = last_elo - opp_elo # Elo difference between teams\n",
    "clean_data['OppElo_last5'] = clean_data.groupby('Team')['Elo_Diff'].transform(\n",
    "    lambda x: x.shift(1).rolling(5, min_periods=1).mean()\n",
    ").fillna(0)\n",
    "\n",
    "# Opponent form & fatigue\n",
    "def opp_feature(col, fill):\n",
    "    return clean_data.merge(\n",
    "        clean_data[['Team', 'Date', col]],\n",
    "        left_on=['Opponent', 'Date'],\n",
    "        right_on=['Team', 'Date'],\n",
    "        how='left', suffixes=('', '_opp')\n",
    "    )[col].fillna(fill)\n",
    "\n",
    "clean_data['Opp_WinRate_last5'] = opp_feature('WinRate_last5', 0) #New feature - opponent win rate in last 5 matches\n",
    "clean_data['Opp_RestDays'] = opp_feature('RestDays', 7) #new feature - opponent rest days\n",
    "clean_data['Opp_Games_last10d'] = opp_feature('Games_last10d', 0) #New feature - opponent games played in last 10 days\n",
    "\n",
    "# Last 30 days rolling avg \n",
    "def last_month(df, stat):\n",
    "    out = []\n",
    "    for team, grp in df.groupby('Team'):\n",
    "        g = grp.set_index('Date')[stat].sort_index()\n",
    "        out.append(g.rolling('30D', min_periods=1).mean().shift(1).reset_index(drop=True))\n",
    "    return pd.concat(out).reset_index(drop=True)\n",
    "\n",
    "for stat in stats_to_avg:\n",
    "    clean_data[f'{stat}_last30'] = last_month(clean_data, stat)\n",
    "\n",
    "# Head to head average\n",
    "def head_to_head(df, stat):\n",
    "    out = []\n",
    "    for (t, o), grp in df.groupby(['Team', 'Opponent']):\n",
    "        out.append(grp[stat].shift(1).expanding().mean().reset_index(drop=True))\n",
    "    return pd.concat(out).reset_index(drop=True)\n",
    "\n",
    "for stat in stats_to_avg:\n",
    "    clean_data[f'head_two_head_{stat}_avg'] = head_to_head(clean_data, stat)\n",
    "\n",
    "# Home vs away diff\n",
    "for stat in ['xG', 'GA']:\n",
    "    clean_data[f'Home_{stat}_last5'] = clean_data.groupby(['Team', 'Venue'])[stat].transform(\n",
    "        lambda x: x.shift(1).rolling(5, min_periods=1).mean()\n",
    "    )\n",
    "    diff = clean_data.groupby('Team')[f'Home_{stat}_last5'].transform('mean') - \\\n",
    "           clean_data.groupby('Team')[stat].transform('mean')\n",
    "    clean_data[f'{stat}_HomeAwayDiff'] = diff.fillna(0)\n",
    "\n",
    "\n",
    "clean_data['xG_Momentum'] = clean_data['xG_last5'] - clean_data['xG_last5'].shift(5).fillna(0) #new feature - xG momentum\n",
    "clean_data['Poss_Momentum'] = clean_data['Poss_last30'] - clean_data['Poss_last30'].shift(5).fillna(0) #new feature - Possession momentum\n",
    "clean_data['SoT_Momentum'] = clean_data['SoT_last30'] - clean_data['SoT_last30'].shift(5).fillna(0) #new feature - Shots on target momentum\n",
    "clean_data['GoalDiff_last5'] = clean_data['GF_last5'] - clean_data['GA_last5'] #new feature - goal difference in last 5 matches\n",
    "clean_data['Goal_Scoring_Rate_5'] = clean_data['GF_last5'] / 5 #new feature - goal scoring rate in last 5 matches\n",
    "clean_data['Goal_Scoring_Rate_30'] = clean_data['GF_last30'] / 30 #new feature - goal scoring rate in last 30 matches\n",
    "\n",
    "clean_data['TotalGoals'] = clean_data['GF'] + clean_data['GA'] #new feature - total goals scored and conceded\n",
    "clean_data['Goals_last5'] = clean_data['GF_last5'] + clean_data['GA_last5'] #New feature - total goals scored and conceded in last 5 matches\n",
    "clean_data['Attacking_Trend'] = clean_data['xG_last5'] - clean_data['xG_last5'].shift(5).fillna(0) #new feature - attacking trend in last 5 matches\n",
    "clean_data['Defensive_Weakness'] = clean_data['GA_last5'] - clean_data['GA_last5'].shift(5).fillna(0) #new feature - defensive weakness in last 5 matches\n",
    "clean_data['Opp_DefWeakness'] = opp_feature('GA_last5', clean_data['GA_last5'].mean()) #new feature - opponent defensive weakness in last 5 matches\n",
    "\n",
    "fill_featrues = [\n",
    "    '_avg', '_last5', '_last30', 'Streak',\n",
    "    'Elo', 'Rest', 'Diff', 'Opp', 'Trend', 'Goals'\n",
    "]\n",
    "#filling null values\n",
    "for c in clean_data.columns:\n",
    "    if clean_data[c].dtype in ['float64', 'int64'] and any(k in c for k in fill_featrues):\n",
    "        clean_data[c] = clean_data[c].fillna(clean_data[c].mean())\n",
    "\n",
    "# Drop raw stats and Date, not needed anymore\n",
    "clean_data.drop(columns=stats_to_avg + ['Date'], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462269a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Top 20 Features: ['TotalGoals', 'Elo_Diff', 'Attendance', 'Elo', 'Poss_last30', 'OppElo_last5', 'Home_xG_last5', 'xG_last30', 'Dist_last30', 'Poss_Momentum', 'xG_last5', 'SoT_Momentum', 'Sh_last30', 'xGA_last30', 'head_two_head_Poss_avg', 'xGA_last5', 'head_two_head_Sh_avg', 'head_two_head_xGA_avg', 'head_two_head_Dist_avg', 'xG_Momentum']\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "clean_data = pd.get_dummies(clean_data, columns=['Team','Opponent'], drop_first=True).dropna().reset_index(drop=True)\n",
    "#droping the target column\n",
    "X = clean_data.drop('Result', axis=1)\n",
    "y = clean_data['Result']\n",
    "\n",
    "# Feature importance just to pick top 20 features, using random forest\n",
    "rf_fs = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
    "rf_fs.fit(X, y)\n",
    "importances = rf_fs.feature_importances_\n",
    "idx = np.argsort(importances)[::-1][:20]\n",
    "top_features = X.columns[idx].tolist()\n",
    "print(\"Selected Top 20 Features:\", top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a74966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation (Training Set)\n",
      "SVM                  | F1: 0.506 ± 0.018 | Acc: 0.507 ± 0.018\n",
      "NaiveBayes           | F1: 0.456 ± 0.016 | Acc: 0.493 ± 0.015\n",
      "GradientBoosting     | F1: 0.609 ± 0.017 | Acc: 0.611 ± 0.016\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "SVM Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "GradientBoosting Best Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "Test Set Performance \n",
      "\n",
      "--- SVM ---\n",
      "Accuracy: 0.51\n",
      "Precision: 0.508\n",
      "Recall: 0.51\n",
      "F1 Score: 0.509\n",
      "Confusion Matrix:\n",
      " [[152  57  65]\n",
      " [ 63  80  62]\n",
      " [ 67  56 153]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.539     0.555     0.547       274\n",
      "           1      0.415     0.390     0.402       205\n",
      "           2      0.546     0.554     0.550       276\n",
      "\n",
      "    accuracy                          0.510       755\n",
      "   macro avg      0.500     0.500     0.500       755\n",
      "weighted avg      0.508     0.510     0.509       755\n",
      "\n",
      "\n",
      "--- GradientBoosting ---\n",
      "Accuracy: 0.589\n",
      "Precision: 0.591\n",
      "Recall: 0.589\n",
      "F1 Score: 0.586\n",
      "Confusion Matrix:\n",
      " [[151  59  64]\n",
      " [ 25 153  27]\n",
      " [ 84  51 141]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.581     0.551     0.566       274\n",
      "           1      0.582     0.746     0.654       205\n",
      "           2      0.608     0.511     0.555       276\n",
      "\n",
      "    accuracy                          0.589       755\n",
      "   macro avg      0.590     0.603     0.592       755\n",
      "weighted avg      0.591     0.589     0.586       755\n",
      "\n",
      "\n",
      "--- NaiveBayes ---\n",
      "Accuracy: 0.494\n",
      "Precision: 0.479\n",
      "Recall: 0.494\n",
      "F1 Score: 0.456\n",
      "Confusion Matrix:\n",
      " [[197  18  59]\n",
      " [101  24  80]\n",
      " [108  16 152]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.485     0.719     0.579       274\n",
      "           1      0.414     0.117     0.183       205\n",
      "           2      0.522     0.551     0.536       276\n",
      "\n",
      "    accuracy                          0.494       755\n",
      "   macro avg      0.474     0.462     0.433       755\n",
      "weighted avg      0.479     0.494     0.456       755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train test split using the top features\n",
    "features_to_use = X[top_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_to_use, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize numeric features\n",
    "num_cols = X_train.select_dtypes(include=[float, int]).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Models we chosed\n",
    "models = {\n",
    "    'SVM': SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Cross validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"\\nCross-Validation (Training Set)\")\n",
    "for name, model in models.items():\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "    acc_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"{name:20s} | F1: {f1_scores.mean():.3f} ± {f1_scores.std():.3f} | \"\n",
    "          f\"Acc: {acc_scores.mean():.3f} ± {acc_scores.std():.3f}\")\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grids = {\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name in ['SVM', 'GradientBoosting']:\n",
    "    grid = GridSearchCV(models[name], param_grids[name], cv=3, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(f\"{name} Best Params: {grid.best_params_}\")\n",
    "\n",
    "best_models['NaiveBayes'] = models['NaiveBayes'].fit(X_train, y_train)\n",
    "\n",
    "# Final test set evaluation\n",
    "print(\"\\nTest Set Performance \")\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "    print(\"Precision:\", round(precision_score(y_test, y_pred, average='weighted'), 3))\n",
    "    print(\"Recall:\", round(recall_score(y_test, y_pred, average='weighted'), 3))\n",
    "    print(\"F1 Score:\", round(f1_score(y_test, y_pred, average='weighted'), 3))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
